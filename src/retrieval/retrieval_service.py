from typing import Any

from wireup import service
from src.retrieval.query_router import QueryRouter
from src.retrieval.query_translator import QueryTranslator
from src.retrieval.answer_generator import AnswerGenerator
from src.retrieval.query_invoice_repository import (
    IQueryInvoiceRepository,
    VectorSearchFilter,
)
from src.retrieval.tools import SearchLineItemsTool, SearchInvoicesTool
from src.core.models import LineItemModel, InvoiceModel


@service
class RetrievalService:
    """
    ⚙️ Retrieval Service (Orchestrator)

    Main service that orchestrates the retrieval workflow:
    1. Calls QueryRouter to analyze intent
    2. Calls QueryTranslator to map args to filters
    3. Calls Repository to execute search
    4. Decides whether to generate an answer or return structured data
    """

    def __init__(
        self,
        query_router: QueryRouter,
        query_translator: QueryTranslator,
        answer_generator: AnswerGenerator,
        query_repository: IQueryInvoiceRepository,
    ) -> None:
        self._query_router: QueryRouter = query_router
        self._query_translator: QueryTranslator = query_translator
        self._answer_generator: AnswerGenerator = answer_generator
        self._query_repository: IQueryInvoiceRepository = query_repository

    async def retrieve(
        self,
        user_query: str,
        is_llm_generated: bool = False,
    ) -> str | list[dict[str, Any]]:
        """
        Main retrieval method that follows the activity diagram flow.

        Args:
            user_query: The natural language query from the user
            is_llm_generated: Whether the query was generated by an LLM

        Returns:
            Either a generated answer string or structured data as a list of dictionaries
        """
        # Step 1: Call QueryRouter to analyze intent and select tool
        routing_result: str | SearchLineItemsTool | SearchInvoicesTool = (
            self._query_router.route(user_query)
        )

        # Step 2: Handle the routing result (either a tool or a text response)
        if isinstance(routing_result, str):
            # If the router returned a text response instead of a tool, return it directly
            return routing_result

        # Step 3: Process the selected tool
        if isinstance(routing_result, SearchLineItemsTool):
            return await self._process_line_items_query(
                user_query, routing_result, is_llm_generated
            )
        elif isinstance(routing_result, SearchInvoicesTool):
            return await self._process_invoices_query(routing_result)
        else:
            raise ValueError(
                f"Unknown tool type returned by router: {type(routing_result)}"
            )

    async def _process_line_items_query(
        self,
        user_query: str,
        criteria: SearchLineItemsTool,
        is_llm_generated: bool,
    ) -> str | list[dict]:
        """
        Process a line items query following the activity diagram flow.
        """
        # Check if the query contains semantic text that requires vector search
        has_semantic_text = bool(criteria.query_text)

        if has_semantic_text:
            # Path A: Semantic Vector Search
            # Generate embeddings for the query text (in a real implementation, we'd use an embedding model)
            # For now, we'll simulate this by using a placeholder
            embedding = (
                await self._generate_embeddings(criteria.query_text)
                if criteria.query_text
                else None
            )

            # Build hybrid search: Vector Search + Match filters
            results = await self._execute_vector_search(criteria, embedding)
        else:
            # Path B: Structured / Keyword Search
            # Generate the MongoDB pipeline using the QueryTranslator
            pipeline = await self._query_translator.generate_line_item_pipeline(
                criteria, None
            )

            # Execute the pipeline using beanie
            results = await LineItemModel.aggregate(pipeline).to_list(length=None)

        # Decision: Check if we should generate an answer or return structured data
        # According to the activity diagram: if results exist and we should generate an answer, use the Answer Generator
        # Otherwise, format and return JSON response
        should_generate_answer = is_llm_generated and len(results) > 0

        if should_generate_answer:
            # Convert results to LineItemModel instances for the answer generator
            line_items = []
            for result in results:
                # Create LineItemModel from the result
                if isinstance(result, dict):
                    # If result is a dict from aggregation
                    line_item = LineItemModel(
                        invoice_id=result.get("invoice_id"),
                        page_number=result.get("page_number", 0),
                        description=result.get("description", ""),
                        quantity=result.get("quantity"),
                        unit_price=result.get("unit_price"),
                        total_amount=result.get("total_amount"),
                        section=result.get("section", ""),
                        item_code=result.get("item_code"),
                        delivery_date=result.get("delivery_date"),
                        search_text=result.get("description", ""),
                        vector=[],  # Empty vector for this use case
                    )
                else:
                    # If result is already a LineItemModel
                    line_item = result
                line_items.append(line_item)

            # Generate a grounded answer using the AnswerGenerator
            answer = self._answer_generator.generate_answer(user_query, line_items)
            return answer
        else:
            # Format and return structured data (JSON Response)
            return results if results else []

    async def _process_invoices_query(
        self,
        criteria: SearchInvoicesTool,
    ) -> list[dict[str, Any]]:
        """
        Process an invoices query following the activity diagram flow.
        """
        # Generate the MongoDB pipeline using the QueryTranslator
        pipeline: list[dict[str, Any]] = (
            self._query_translator.generate_invoice_pipeline(criteria)
        )

        # Execute the pipeline using beanie
        results: list[dict[str, Any]] = await InvoiceModel.aggregate(pipeline).to_list(
            length=None
        )

        # For invoice queries, we always return structured data
        return results if results else []

    async def _generate_embeddings(self, text: str) -> list[float]:
        """
        Generate vector embeddings for the given text.
        In a real implementation, this would call an embedding model.
        """
        # Placeholder implementation - in a real system, this would call an embedding API
        # For now, return a dummy embedding vector
        # In a real implementation, you might use something like:
        # from google.genai import embedding
        # return await embedding.generate(text)
        return [0.1] * 768  # Simulated 768-dim embedding

    async def _execute_vector_search(
        self, criteria: SearchLineItemsTool, embedding: list[float] | None
    ) -> list[dict]:
        """
        Execute vector search with filters.
        """
        if not embedding:
            # If no embedding, fall back to regular search
            pipeline = await self._query_translator.generate_line_item_pipeline(
                criteria, None
            )
            return await LineItemModel.aggregate(pipeline).to_list(length=None)

        # Create VectorSearchFilter from the criteria
        filters = VectorSearchFilter(
            delivery_date_from=None,  # Would need to parse from criteria if available
            delivery_date_to=None,  # Would need to parse from criteria if available
            total_amount_min=criteria.min_amount,
            total_amount_max=criteria.max_amount,
            page_number=criteria.page_number,
            invoice_ids=None,  # Would need to resolve invoice IDs from criteria
            sender_names=[criteria.sender_name] if criteria.sender_name else None,
        )

        # Execute vector search using the repository
        search_results = await self._query_repository.vector_search(
            query_embedding=embedding, top_k=criteria.limit, filters=filters
        )

        # Convert SearchResult objects to dictionaries for consistency
        results = []
        for search_result in search_results:
            result_dict = {
                "description": search_result.line_item.description,
                "quantity": search_result.line_item.quantity,
                "unit_price": search_result.line_item.unit_price,
                "total_amount": search_result.line_item.total_amount,
                "page_number": search_result.line_item.page_number,
                "delivery_date": search_result.line_item.delivery_date,
                "section": search_result.line_item.section,
                "item_code": search_result.line_item.item_code,
                "invoice_number": search_result.invoice.invoice_number,
                "sender_name": search_result.invoice.sender_name,
                "invoice_date": search_result.invoice.invoice_date,
                "score": search_result.similarity_score,
            }
            results.append(result_dict)

        return results
